{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.impute import SimpleImputer\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "import rpy2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mord import LogisticIT\n",
    "import warnings \n",
    "import copy \n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "SEED = 777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>married</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>occupation</th>\n",
       "      <th>time_in_area</th>\n",
       "      <th>dual_income</th>\n",
       "      <th>num_people_household</th>\n",
       "      <th>num_children_household</th>\n",
       "      <th>home_status</th>\n",
       "      <th>home_type</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income  sex  married  age  education  occupation  time_in_area  \\\n",
       "0       9    2      1.0    5        4.0         5.0           5.0   \n",
       "1       9    1      1.0    5        5.0         5.0           5.0   \n",
       "2       9    2      1.0    3        5.0         1.0           5.0   \n",
       "3       1    2      5.0    1        2.0         6.0           5.0   \n",
       "4       1    2      5.0    1        2.0         6.0           3.0   \n",
       "\n",
       "   dual_income  num_people_household  num_children_household  home_status  \\\n",
       "0            3                   3.0                       0          1.0   \n",
       "1            3                   5.0                       2          1.0   \n",
       "2            2                   3.0                       1          2.0   \n",
       "3            1                   4.0                       2          3.0   \n",
       "4            1                   4.0                       2          3.0   \n",
       "\n",
       "   home_type  ethnicity  language  \n",
       "0        1.0        7.0       NaN  \n",
       "1        1.0        7.0       1.0  \n",
       "2        3.0        7.0       1.0  \n",
       "3        1.0        7.0       1.0  \n",
       "4        1.0        7.0       1.0  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['income','sex','married','age','education','occupation',\n",
    "             'time_in_area','dual_income','num_people_household',\n",
    "             'num_children_household','home_status','home_type','ethnicity',\n",
    "             'language']\n",
    "df = pd.read_csv('marketing.data', delimiter=\" \",header=None, names=col_names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.19403980874013121\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(df['income'])\n",
    "X = np.array(df.drop('income',axis=1))\n",
    "\n",
    "plt.bar(pd.value_counts(Y).index,pd.value_counts(Y).values/len(Y))\n",
    "plt.show()\n",
    "\n",
    "print(f\"Baseline Accuracy: {pd.value_counts(Y).values[0]/len(Y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data 80-20 into a train and a test set using stratified random sampling to preserve the proportion of classes in the response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size=.2, stratify = Y, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a KNN Imputer\n",
    "Define a class to impute missing values in each feature using K-Nearest-Neighbors Classifier trained to predict the non-missing values using the other features. Feature classifiers are only fit on the training data in each step and do not see the test or validation data during training. This is to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class KNNImputer():\n",
    "    def __init__(self):\n",
    "        # Try an array of n values for each classifier\n",
    "        self.model = GridSearchCV(KNeighborsClassifier(),{'n_neighbors':[5,10,15,20]}, cv=3, n_jobs=-1)\n",
    "        self.model_list = [None]\n",
    "        self.X = np.array([])\n",
    "        \n",
    "    def fit(self, X, verbose = 0):\n",
    "        # create deep copy to avoid altering the original data\n",
    "        self.X = copy.deepcopy(X)\n",
    "\n",
    "        if len(self.X.shape)==1 or self.X.shape[1]==0:\n",
    "            self.X = self.X.reshape(-1,1)\n",
    "\n",
    "        self.model_list = [None]*(self.X.shape[1])\n",
    "        \n",
    "        # count of missing values per column\n",
    "        col_nan_count = np.sum(np.isnan(self.X),axis=0)\n",
    "    \n",
    "        # Indexes of columns with at least 1 missing value sorted from most to least missing values\n",
    "        col_nan_count_sorted = sorted(enumerate(col_nan_count),key=lambda x: x[1], reverse=True)\n",
    "        col_ix_sorted = [tup[0] for tup in col_nan_count_sorted if tup[1]>0]\n",
    "\n",
    "        tot_nan = sum(np.sum(np.isnan(self.X),axis=0))\n",
    "        \n",
    "        # for each column with missing values, sorted from most missing values to least..\n",
    "        for i in col_ix_sorted:\n",
    "            target = self.X[:,i].reshape(-1,1) # feature to fill missing values for\n",
    "            features = np.delete(self.X, i, axis=1) # features used to predict missing values\n",
    "            \n",
    "            # scale features so that each has equal sway in KNN classification\n",
    "            scaler = StandardScaler()\n",
    "            features = scaler.fit_transform(features)\n",
    "            \n",
    "            # seperate missing values (to be predicted) and existing values (used to train classifier)\n",
    "            target_train = target[[not na for na in np.isnan(target)]]\n",
    "            target_missing = target[np.isnan(target)]\n",
    "            \n",
    "            # isolate observations with corresponding target values for training\n",
    "            features_train = features[[not na for na in np.isnan(target).flatten()]]\n",
    "            # temporarily fill in missing values in observation features used to train imputer\n",
    "            mean_imputer = SimpleImputer(strategy='most_frequent')\n",
    "            features_train = mean_imputer.fit_transform(features_train)\n",
    "            \n",
    "            # isolate feature observations with no corresponding target feature for prediction\n",
    "            features_missing = features[np.isnan(target).flatten()]\n",
    "            features_missing = mean_imputer.fit_transform(features_missing)\n",
    "            \n",
    "            # train model and store it in mode list corresponding to feature index\n",
    "            self.model_list[i] = self.model.fit(features_train, target_train)\n",
    "\n",
    "            in_sample_acc = self.model_list[i].score(features_train, target_train)\n",
    "            #if False:\n",
    "            #    print(f\"Column {i} - filled {col_nan_count[i]} NaN values - in sample accuracy: {in_sample_acc}\")\n",
    "            \n",
    "            # predict in missing values\n",
    "            predictions_missing = self.model.predict(features_missing)\n",
    "            # fill missing values in with predictions\n",
    "            target[np.isnan(target)] = predictions_missing\n",
    "            self.X[:,i] = target.flatten()\n",
    "        \n",
    "        # for each column without missing values  \n",
    "        non_na_col_ix = set(range(0,self.X.shape[1])).difference(col_ix_sorted)\n",
    "        #train model to predict the column features using other features. No missing values to fill in.\n",
    "        for i in non_na_col_ix:\n",
    "            target = self.X[:,i].reshape(-1,1)\n",
    "            features = np.delete(self.X, i, axis=1)\n",
    "            \n",
    "            self.model_list[i] = self.model.fit(features, target)\n",
    "            \n",
    "    def fit_transform(self, X, verbose = 0):\n",
    "        X_backup = copy.deepcopy(X)\n",
    "    \n",
    "        self.fit(X, verbose = verbose)\n",
    "        assert sum(sum(np.isnan(X))) == sum(sum(np.isnan(X_backup)))\n",
    "        return self.X\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.X = copy.deepcopy(X)\n",
    "        col_nan_count = np.sum(np.isnan(X),axis=0)\n",
    "        col_ixs = [i for i, count in enumerate(col_nan_count) if count>0]\n",
    "\n",
    "        for i in col_ixs:\n",
    "            target = self.X[:,i].reshape(-1,1)\n",
    "            features = np.delete(self.X, i, axis=1)\n",
    "            features_missing = features[np.isnan(target).flatten()]\n",
    "            if len(features_missing.shape)==1:\n",
    "                features_missing = features_missing.reshape(-1,1)\n",
    "            features_missing = mean_imputer.fit_transform(features_missing)\n",
    "\n",
    "            predictions_missing = self.model_list[i].predict(features_missing)\n",
    "\n",
    "            target[np.isnan(target)] = predictions_missing\n",
    "            \n",
    "            # Replace features \n",
    "            self.X[:,i] = target.flatten()\n",
    "\n",
    "        return self.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def col_ix(label):\n",
    "    col_list = ['sex','married','age','education','occupation',\n",
    "                'time_in_area','dual_income','num_people_household',\n",
    "                'num_children_household','home_status','home_type','ethnicity',\n",
    "                'language']\n",
    "\n",
    "    return col_list.index(label)\n",
    "\n",
    "# Artificial predictor to satisfy Pipeline's requirement that the last class needs to be an estimator \n",
    "# (able to take a Y parameter)\n",
    "class LastEstimator():\n",
    "    def __init__(self):\n",
    "        self.encoder=None\n",
    "    def fit(self,X,Y=None):\n",
    "        return self\n",
    "    def transform(self, X, Y=None):\n",
    "        return X\n",
    "    def fit_transform(self, X, Y=None):\n",
    "        #print(\"LastEstimator.fit_transform\")\n",
    "        return X\n",
    "\n",
    "# Class to convert 0 dimensional NP arrays to 1 dimensional NP arrays for compatibility \n",
    "class reshaper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.x = 0\n",
    "\n",
    "    def fit(self, X=None, Y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, Y=None):\n",
    "        if type(X) is pd.Series:\n",
    "            X=X.values\n",
    "        return X.reshape(-1, 1)\n",
    "\n",
    "# Class to convert sparse scipy arrays NP arrays for compatibility \n",
    "class ToDenseArray():\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def fit(self, X, Y=None):\n",
    "        return self\n",
    "    def transform(self, X, Y=None):\n",
    "        return X.toarray()\n",
    "\n",
    "# Define pipeline to preprocess numeric features:\n",
    "    # age, time_in_area, num_people_household, num_child_household\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('reshape', reshaper()),\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('deskew',PowerTransformer()),\n",
    "    ('predict',LastEstimator())\n",
    "    ]) # scale and deskew each numeric feature\n",
    "\n",
    "# Define pipeline to preprocess binary features:\n",
    "    # sex, married\n",
    "binary_pipeline = Pipeline([\n",
    "    ('reshape', reshaper()),\n",
    "    ('OHE', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('to_dense',ToDenseArray()),\n",
    "    ('predict',LastEstimator())\n",
    "]) # # Make dummy variables for both possible values of each binary feature\n",
    "\n",
    "# Define pipeline to preprocess numeric features:\n",
    "    # dual_income, education, occupation, home_status, home_type, ethnicity, language\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('reshape', reshaper()),\n",
    "    ('OHE', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('to_dense',ToDenseArray()),\n",
    "    ('predict',LastEstimator())\n",
    "]) # Make dummy variables for each possible value of each categorical feature\n",
    "\n",
    "# define columnransformer to apply preprocessing steps to each feature\n",
    "ct = ColumnTransformer([\n",
    "    ('sex', binary_pipeline, col_ix('sex')),\n",
    "    ('married', binary_pipeline, col_ix('married')),\n",
    "    ('dual_income', categorical_pipeline, col_ix('dual_income')),\n",
    "    ('education', categorical_pipeline, col_ix('education')),\n",
    "    ('occupation', categorical_pipeline, col_ix('occupation')),\n",
    "    ('home_status', categorical_pipeline, col_ix('home_status')),\n",
    "    ('home_type', categorical_pipeline, col_ix('home_type')),\n",
    "    ('ethnicicty', categorical_pipeline, col_ix('ethnicity')),\n",
    "    ('language', categorical_pipeline, col_ix('language')),\n",
    "    ('age', numeric_pipeline, col_ix('age')),\n",
    "    ('time_in_area', numeric_pipeline, col_ix('time_in_area')),\n",
    "    ('num_people_household', numeric_pipeline, col_ix('num_people_household')),\n",
    "    ('num_children_household', numeric_pipeline, col_ix('num_children_household')),  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(pipeline_gridsearch):\n",
    "    estimator = pipeline_gridsearch.best_estimator_\n",
    "    \n",
    "    best_params = estimator.named_steps['clf'].best_params_\n",
    "    best_score_cv = pipeline_gridsearch.best_score_\n",
    "    score_std = pipeline_gridsearch.cv_results_['std_test_score'][pipeline_gridsearch.best_index_]\n",
    "    train_score = accuracy_score(estimator.predict(x_train), y_train)\n",
    "    test_score = accuracy_score(estimator.predict(x_test), y_test)\n",
    "    \n",
    "    estimator.fit(x_train, y_train)\n",
    "    test_score_refit = accuracy_score(estimator.predict(x_test), y_test)\n",
    "\n",
    "    print('{:<40}: {:<50}'.format('Best parameters', repr(best_params)))\n",
    "    print('{:<40}: {:<50}'.format('Best validation score', '{} +-{}'.format(round(best_score_cv,3),round(score_std,3))))\n",
    "    print('{:<40}: {:<50}'.format('Train score', round(train_score,3)))\n",
    "    print('{:<40}: {:<50}'.format('Test score', round(test_score,3)))\n",
    "    print('{:<40}: {:<50}'.format('Test score (all training data)', test_score_refit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. K-Nearest-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', <__main__.KNNImputer object at 0x00000253985BEE48>), ('preprocess', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('sex', Pipeline(memory=None,\n",
       "     steps=[('reshape', reshaper()), ('OHE', OneHotEnco...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try odd values between 5 and 29 for N\n",
    "KNN_param_grid = {\n",
    "    'n_neighbors': [x*2+1 for x in range(2,14)]\n",
    "}\n",
    "\n",
    "KNN_gridsearch = GridSearchCV(KNeighborsClassifier(), KNN_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "KNN_pipeline = Pipeline([\n",
    "    ('impute', KNNImputer()),\n",
    "    ('preprocess', ct),\n",
    "    ('clf', KNN_gridsearch)\n",
    "    ])\n",
    "\n",
    "KNN_pipeline_gridsearch = GridSearchCV(KNN_pipeline, param_grid={}, cv=3, n_jobs=-1)\n",
    "\n",
    "KNN_pipeline_gridsearch.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   KNN CLASSIFIER RESULTS                   \n",
      "Best parameters                         : {'n_neighbors': 23}                               \n",
      "Best validation score                   : 0.324 +-0.007                                     \n",
      "Train score                             : 0.394                                             \n",
      "Test score                              : 0.326                                             \n",
      "Test score (all training data)          : 0.3257365202890495                                \n"
     ]
    }
   ],
   "source": [
    "print(\"{:^60}\".format(\"KNN CLASSIFIER RESULTS\"))\n",
    "report_metrics(KNN_pipeline_gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Logistic Regression - No Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', <__main__.KNNImputer object at 0x00000253AB28A9E8>), ('preprocess', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('sex', Pipeline(memory=None,\n",
       "     steps=[('reshape', reshaper()), ('OHE', OneHotEnco...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_param_grid = {\n",
    "}\n",
    "\n",
    "LR_gridsearch = GridSearchCV(LogisticRegression(), LR_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "LR_pipeline = Pipeline([\n",
    "    ('impute', KNNImputer()),\n",
    "    ('preprocess', ct),\n",
    "    ('clf', LR_gridsearch)\n",
    "    ])\n",
    "\n",
    "LR_pipeline_gridsearch = GridSearchCV(LR_pipeline, param_grid={}, cv=3, n_jobs=-1)\n",
    "LR_pipeline_gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                LOGISTIC REGRESSION RESULTS                 \n",
      "Best parameters                         : {}                                                \n",
      "Best validation score                   : 0.334 +-0.004                                     \n",
      "Train score                             : 0.362                                             \n",
      "Test score                              : 0.342                                             \n",
      "Test score (all training data)          : 0.3424124513618677                                \n"
     ]
    }
   ],
   "source": [
    "print(\"{:^60}\".format(\"LOGISTIC REGRESSION RESULTS\"))\n",
    "report_metrics(LR_pipeline_gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Logistic Regression -  L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', <__main__.KNNImputer object at 0x00000253AB3534E0>), ('preprocess', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('sex', Pipeline(memory=None,\n",
       "     steps=[('reshape', reshaper()), ('OHE', OneHotEnco...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR1_param_grid = {\n",
    "    'penalty': ['l1'],\n",
    "    'C':[12,11,10,9,8,7,6]\n",
    "}\n",
    "\n",
    "LR1_gridsearch = GridSearchCV(LogisticRegression(), LR1_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "LR1_pipeline = Pipeline([\n",
    "    ('impute', KNNImputer()),\n",
    "    ('preprocess', ct),\n",
    "    ('clf', LR1_gridsearch)\n",
    "    ])\n",
    "\n",
    "LR1_pipeline_gridsearch = GridSearchCV(LR1_pipeline, param_grid={}, cv=3, n_jobs=-1)\n",
    "LR1_pipeline_gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          LOGISTIC REGRESSION (L1 PENALTY) RESULTS          \n",
      "Best parameters                         : {'C': 9, 'penalty': 'l1'}                         \n",
      "Best validation score                   : 0.334 +-0.004                                     \n",
      "Train score                             : 0.363                                             \n",
      "Test score                              : 0.34                                              \n",
      "Test score (all training data)          : 0.33852140077821014                               \n"
     ]
    }
   ],
   "source": [
    "print(\"{:^60}\".format(\"LOGISTIC REGRESSION (L1 PENALTY) RESULTS\"))\n",
    "report_metrics(LR1_pipeline_gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Logistic Regression - L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', <__main__.KNNImputer object at 0x0000025397D746D8>), ('preprocess', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('sex', Pipeline(memory=None,\n",
       "     steps=[('reshape', reshaper()), ('OHE', OneHotEnco...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR2_param_grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'C':[10, 8, 6, 5, 4, 2]\n",
    "}\n",
    "\n",
    "LR2_gridsearch = GridSearchCV(LogisticRegression(), LR2_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "LR2_pipeline = Pipeline([\n",
    "    ('impute', KNNImputer()),\n",
    "    ('preprocess', ct),\n",
    "    ('clf', LR1_gridsearch)\n",
    "    ])\n",
    "\n",
    "LR2_pipeline_gridsearch = GridSearchCV(LR2_pipeline, param_grid={}, cv=3, n_jobs=-1)\n",
    "LR2_pipeline_gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          LOGISTIC REGRESSION (L2 PENALTY) RESULTS          \n",
      "Best parameters                         : {'C': 11, 'penalty': 'l1'}                        \n",
      "Best validation score                   : 0.335 +-0.004                                     \n",
      "Train score                             : 0.363                                             \n",
      "Test score                              : 0.337                                             \n",
      "Test score (all training data)          : 0.33740967204002226                               \n"
     ]
    }
   ],
   "source": [
    "print(\"{:^60}\".format(\"LOGISTIC REGRESSION (L2 PENALTY) RESULTS\"))\n",
    "report_metrics(LR2_pipeline_gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LogisticIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', <__main__.KNNImputer object at 0x00000253AB364400>), ('preprocess', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('sex', Pipeline(memory=None,\n",
       "     steps=[('reshape', reshaper()), ('OHE', OneHotEnco...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRIT_param_grid = {\n",
    "    'alpha':[0.05,0.075,0.1,0.2,0.3,0.4]\n",
    "}\n",
    "\n",
    "LRIT_gridsearch = GridSearchCV(LogisticIT(), LRIT_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "LRIT_pipeline = Pipeline([\n",
    "    ('impute', KNNImputer()),\n",
    "    ('preprocess', ct),\n",
    "    ('clf', LRIT_gridsearch)\n",
    "    ])\n",
    "\n",
    "LRIT_pipeline_gridsearch = GridSearchCV(LRIT_pipeline, param_grid={}, cv=3, n_jobs=-1)\n",
    "LRIT_pipeline_gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ORDINAL LOGISTIC (IMMEDIATE THRESHOLD) RESULTS       \n",
      "Best parameters                         : {'alpha': 0.05}                                   \n",
      "Best validation score                   : 0.325 +-0.006                                     \n",
      "Train score                             : 0.327                                             \n",
      "Test score                              : 0.32                                              \n",
      "Test score (all training data)          : 0.32017787659811003                               \n"
     ]
    }
   ],
   "source": [
    "print(\"{:^60}\".format(\"ORDINAL LOGISTIC (IMMEDIATE THRESHOLD) RESULTS\"))\n",
    "report_metrics(LRIT_pipeline_gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', <__main__.KNNImputer object at 0x00000253CA6D8320>), ('preprocess', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('sex', Pipeline(memory=None,\n",
       "     steps=[('reshape', reshaper()), ('OHE', OneHotEnco...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_param_grid = {\n",
    "    'n_estimators': [x*100 for x in range(1,10)]\n",
    "}\n",
    "\n",
    "RF_gridsearch = GridSearchCV(RandomForestClassifier(), RF_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "RF_pipeline = Pipeline([\n",
    "    ('impute', KNNImputer()),\n",
    "    ('preprocess', ct),\n",
    "    ('clf', RF_gridsearch)\n",
    "    ])\n",
    "\n",
    "RF_pipeline_gridsearch = GridSearchCV(RF_pipeline, param_grid={}, cv=3, n_jobs=-1)\n",
    "RF_pipeline_gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   RANDOM FOREST RESULTS                    \n",
      "Best parameters                         : {'n_estimators': 200}                             \n",
      "Best validation score                   : 0.317 +-0.008                                     \n",
      "Train score                             : 0.87                                              \n",
      "Test score                              : 0.31                                              \n",
      "Test score (all training data)          : 0.31017231795441913                               \n"
     ]
    }
   ],
   "source": [
    "print(\"{:^60}\".format(\"RANDOM FOREST RESULTS\"))\n",
    "report_metrics(RF_pipeline_gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', <__main__.KNNImputer object at 0x0000025397D7B470>), ('preprocess', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('sex', Pipeline(memory=None,\n",
       "     steps=[('reshape', reshaper()), ('OHE', OneHotEnco...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "XGBC1_param_grid = {\n",
    "    'learning_rate':[0.1],\n",
    "    'n_estimators':[1000],\n",
    "    'max_depth':[5],\n",
    "    'min_child_weight':[1],\n",
    "    'gamma':[0],\n",
    "    'subsample':[0.8],\n",
    "    'colsample_bytree':[0.8],\n",
    "    'scale_pos_weight':[1],\n",
    "    'max_depth': range(3,10,2),\n",
    "    'min_child_weight': range(1,6,2)\n",
    "}\n",
    "\n",
    "XGBC1_gridsearch = GridSearchCV(XGBClassifier(), XGBC1_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "XGBC1_pipeline = Pipeline([\n",
    "    ('impute', KNNImputer()),\n",
    "    ('preprocess', ct),\n",
    "    ('clf', XGBC1_gridsearch)\n",
    "    ])\n",
    "\n",
    "XGBC1_pipeline_gridsearch = GridSearchCV(XGBC1_pipeline, param_grid={}, cv=3, n_jobs=-1)\n",
    "XGBC1_pipeline_gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BOOSTED FOREST CLASSIFIER #1 RESULTS            \n",
      "Best parameters                         : {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 1, 'subsample': 0.8}\n",
      "Best validation score                   : 0.329 +-0.007                                     \n",
      "Train score                             : 0.557                                             \n",
      "Test score                              : 0.338                                             \n",
      "Test score (all training data)          : 0.3379655364091162                                \n"
     ]
    }
   ],
   "source": [
    "print(\"{:^60}\".format(\"BOOSTED FOREST CLASSIFIER #1 RESULTS\"))\n",
    "report_metrics(XGBC1_pipeline_gridsearch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
